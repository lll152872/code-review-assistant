import chromadb
import libcst as cst
from chromadb.utils import embedding_functions
from langchain_ollama import ChatOllama
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

llm=ChatOllama(
    model="qwen3:1.7b",
    temperature=0
)
def ai(user_code,rules_text):
    ai_response=chain.invoke

client = chromadb.Client()
default_ef=embedding_functions.DefaultEmbeddingFunction()
collection =client.get_or_create_collection(
    name="test",
    embedding_function=default_ef
)
rules_data = [
    {
        "id": "R1", 
        "desc": "ç¦æ­¢åœ¨å¾ªç¯ä¸­åˆ›å»ºæ•°æ®åº“è¿æ¥ï¼Œè¿™ä¼šå¯¼è‡´è¿æ¥æ± è€—å°½ã€‚", 
        "keywords": "db.connect, new Connection, DriverManager.getConnection",
        "tags": ["loop", "database"]
    },
    {
        "id": "R2", 
        "desc": "ç¦æ­¢åœ¨å¾ªç¯ä¸­æ‰“å°æ—¥å¿—ï¼Œè¿™ä¼šäº§ç”Ÿå¤§é‡ IO å¼€é”€ï¼Œå½±å“æ€§èƒ½ã€‚", 
        "keywords": "print, logger.info, console.log",
        "tags": ["loop", "performance"]
    },
    {
        "id": "R3", 
        "desc": "å¾ªç¯å˜é‡å‘½åç¦æ­¢ä½¿ç”¨å•ä¸ªå­—æ¯å¦‚ i, jï¼Œåº”ä½¿ç”¨å…·æœ‰ä¸šåŠ¡å«ä¹‰çš„åç§°ã€‚", 
        "keywords": "for i in, for j in, range(i)",
        "tags": ["loop", "naming"]
    }
]
docs_to_store = [f"{r['desc']} Keywords: {r['keywords']}" for r in rules_data]
collection.add(
    documents=docs_to_store,
    ids=[r["id"] for r in rules_data],
    metadatas=[{"tags": r["tags"]} for r in rules_data] # å…³é”®ï¼šç”¨æ ‡ç­¾åˆ†ç±»
)
class fenxi(cst.CSTVisitor):
    def __init__(self):
        self.is_loop=False
        self.action=[]
    def visit_For(self, node):
        self.is_loop = True
        # ç»§ç»­éå†å¾ªç¯ä½“å†…éƒ¨
        return True 

    def leave_For(self, node):
        self.is_loop = False # ç¦»å¼€å¾ªç¯

    def visit_Call(self, node):
        # æå–å‡½æ•°è°ƒç”¨çš„åå­—ï¼Œä½œä¸ºâ€œåŠ¨ä½œæŒ‡çº¹â€
        # ä¾‹å¦‚: db.connect() -> æå– "connect"
        #       print(...)    -> æå– "print"
        func_name = ""
        if isinstance(node.func, cst.Name):
            func_name = node.func.value
        elif isinstance(node.func, cst.Attribute):
            # å¤„ç† obj.method() çš„æƒ…å†µ
            func_name = node.func.attr.value
            
        if func_name:
            self.actions.append(func_name)
user_code = """
for i in range(10):
    # é”™è¯¯ 1: åœ¨å¾ªç¯é‡Œè¿åº“ (è§¦å‘ R1)
    db.connect() 
    
    # é”™è¯¯ 2: åœ¨å¾ªç¯é‡Œæ‰“å° (è§¦å‘ R2)
    print("Processing item " + str(i))
    
    # æ­£ç¡®: æ¨¡æ‹Ÿä¸€ä¸ªæ™®é€šæ“ä½œï¼Œåº“é‡Œæ²¡è¿™æ¡è§„åˆ™ï¼Œä¸åº”æŠ¥é”™
    item = process_data(i)
"""

print(f"\nğŸ‘€ å¾…å®¡æŸ¥ä»£ç :\n{user_code}")
wrapper = cst.metadata.MetadataWrapper(cst.parse_module(user_code))
visitor = fenxi()
wrapper.visit(visitor)

# åˆ†æç»“æœ
structure_tags = ["loop"] if visitor.is_loop else []
detected_actions = visitor.actions # ["connect", "print", "process_data"]

print(f"ğŸ” [AST åˆ†æ] ç»“æ„æ ‡ç­¾: {structure_tags}, åŠ¨ä½œæŒ‡çº¹: {detected_actions}")

# --- é˜¶æ®µ B: ç²¾å‡†ç‰¹å¾æ£€ç´¢ (è§£å†³æ¼æŸ¥å’Œæ— æ•°æ¡ç»“æœ) ---
triggered_rules = []

if "loop" in structure_tags:
    # ç­–ç•¥ï¼šé’ˆå¯¹æ¯ä¸€ä¸ªåŠ¨ä½œï¼Œéƒ½å»åº“é‡ŒæŸ¥ä¸€æ¬¡ (ç‚¹å¯¹ç‚¹)
    for action in detected_actions:
        print(f"\nğŸ”„ æ­£åœ¨æ£€ç´¢ç‰¹å¾: '{action}' ...")
        
        results = collection.query(
            query_texts=[action], # ç”¨åŠ¨ä½œå (å¦‚ connect) å»åŒ¹é… Keywords
            where={"tags": {"$in": ["loop"]}}, # é™å®šåªåœ¨ loop æ ‡ç­¾é‡ŒæŸ¥
            n_results=1 # æ¯ä¸ªåŠ¨ä½œåªå–æœ€ç›¸å…³çš„ä¸€æ¡
        )
        
        # æ£€æŸ¥è·ç¦»ï¼Œåªæœ‰è¶³å¤Ÿè¿‘æ‰ç®—å‘½ä¸­
        if results['distances'][0][0] < 0.35:
            rule_id = results['ids'][0][0]
            rule_content = results['documents'][0][0]
            
            # å»é‡ï¼šé˜²æ­¢ä¸åŒåŠ¨ä½œè§¦å‘åŒä¸€æ¡è§„åˆ™
            if rule_id not in triggered_rules:
                triggered_rules.append(rule_id)
                print(f"âœ… å‘½ä¸­è§„åˆ™ [{rule_id}]: {rule_content[:30]}...")
            else:
                print(f"â™»ï¸ è§„åˆ™ [{rule_id}] å·²è§¦å‘ï¼Œè·³è¿‡ã€‚")
        else:
            print(f"âšª æœªæ‰¾åˆ°ç›¸å…³è§„åˆ™ (è·ç¦»: {results['distances'][0][0]:.2f})")

# --- é˜¶æ®µ C: æ±‡æ€»å¹¶ç”Ÿæˆ Prompt ---
if triggered_rules:
    # æ ¹æ® ID æ‹¿å›å®Œæ•´çš„è§„åˆ™æè¿°ç»™ AI çœ‹
    final_rules_data = collection.get(ids=triggered_rules)
    
    prompt = f"""
    ä½ æ˜¯ä¸€ä¸ªèµ„æ·±ä»£ç å®¡æŸ¥ä¸“å®¶ã€‚è¯·å®¡æŸ¥ä»¥ä¸‹ä»£ç ã€‚
    
    ç”¨æˆ·ä»£ç :
    {user_code}
å‚è€ƒè§„åˆ™ (å¿…é¡»ä¸¥æ ¼æ£€æŸ¥è¿™äº›ç‚¹):
    {final_rules_data['documents']}
    
    è¯·æŒ‡å‡ºä»£ç ä¸­è¿åäº†å“ªäº›è§„åˆ™ï¼Œå¹¶ç»™å‡ºä¿®æ”¹å»ºè®®ã€‚
    """
    
    # --- é˜¶æ®µ D: è°ƒç”¨ AI ---
    ai_response = ai(prompt)
    print(ai_response)
else:
    print("\nâœ… ä»£ç å®¡æŸ¥é€šè¿‡ï¼Œæœªå‘ç°æ˜æ˜¾è¿è§„ã€‚")